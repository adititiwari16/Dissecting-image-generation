# Image Disection Using Stable Diffusion
This project explores the use of Stable Diffusion, a powerful text-to-image diffusion model, combined with ControlNet to generate images based on user-defined prompts and depth maps. ControlNet allows for additional control over the spatial layout and depth information within the generated images.

### Requirements:

Python 3.7+
PyTorch (tested with 1.13.1)
Transformers (tested with 4.22.0)
Diffusers (tested with 0.8.0)
Torchvision
Installation:

### Create a virtual environment (recommended)

### Install required packages using pip

### References:

Stable Diffusion: From Text to Image
ControlNet: Interactive Image Generation with Latent Noise Control
Diffusers Library [invalid URL removed]


